During this homework I experienced some interesting things. 

My first prompt was experimenting with categorizing different movies and I encountered interesting things. 

I notices that GPT 5 nano was more scared of categorizing a movie in the wrong genre. It would either categorize it but state it is not quite sure, or straight up create a category that it wasn't sure where it was. I notice that the hesitation was in movies that came 

Then I tried 4o mini and gpt 3.5 turbo and they just decided to guess and the surpising thing is that they guessed correctly. What I did noticed is that gpt 5 was more consistent with its categorization that the other models. The other two models were switching categorizations specially between action and thriller movies. 

My second prompt was all about creating ascii art. Specifically I asked for a cat figure. 

I was surprised they all gave me similar results, if not identical. They all gave me a very simple drawing of a cat and all the models gave me pretty much the same cat which is the following. 
```
 /\_/\  
( o.o ) 
 > ^ <  
```

If anything gpt 5 gave me then a different cat, and gpt 3.5 turbo gave me the same cat, but the ears were not alight with the rest of the drawing. 

However just with my small experimentation with this specific prompt it looks like the models are really good when it comes to creating art with ascii characters. 
